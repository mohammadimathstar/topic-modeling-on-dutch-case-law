{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b89b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the pipeline for the model 'nl_core_news_lg': \n",
      "\t['tok2vec', 'morphologizer', 'lemmatizer', 'attribute_ruler', 'ner', 'company_name_detector', 'merge_entities']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "from utils import load_eviction_case_identifiers, extract_eviction_case_text\n",
    "from utils import clean_texts, prepare_topic_modeling_corpus, selection_of_number_of_topics\n",
    "from utils import visualize_topics, generate_topic_distributions\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b29f9",
   "metadata": {},
   "source": [
    "## Preprocessing Description\n",
    "\n",
    "In this preprocessing phase, we perform the following steps to prepare the data for topic modeling:\n",
    "\n",
    "#### Load Eviction Case Identifiers:\n",
    "\n",
    "- `load_eviction_case_identifiers()` function:\n",
    "it loads the European Case Law Identifier (ECLI) codes associated with eviction cases.\n",
    "\n",
    "- `extract_eviction_case_text()` function:\n",
    "we extract the full text of the judgments for the eviction cases. This function takes:\n",
    "     - the list of ECLI codes and retrieves the corresponding judgment texts from a preloaded dataset.\n",
    "\n",
    "- `clean_texts()` function:\n",
    "During this process, we perform the following steps:\n",
    "    - Lemmatization: Convert words to their base or dictionary form (lemma).\n",
    "    - Lowercasing: Convert all text to lowercase to ensure uniformity.\n",
    "    - Stop Word Removal: Exclude common stop words and legal terms that are not relevant to the analysis.\n",
    "    - Token Filtering: Remove non-alphabetic tokens and words with fewer than four characters.\n",
    "    - Entity Removal: Exclude tokens that are part of named entities, as these may not contribute meaningfully to the topic modeling.\n",
    "    - Save the Cleaned Data:\n",
    "\n",
    "This ensures that the preprocessed data is ready for the subsequent topic modeling step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce6c13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5047 ecli numbers of eviction cases.\n",
      "There are 5021 eviction-related cases with texts (26 cases with no text).\n"
     ]
    }
   ],
   "source": [
    "# load ECLI numbers and \n",
    "eviction_ecli = load_eviction_case_identifiers()\n",
    "eviction_ecli_with_texts, eviction_texts = extract_eviction_case_text(eviction_ecli)\n",
    "\n",
    "ecli_nos, cleaned_texts = clean_texts(eviction_ecli_with_texts, eviction_texts, \"./data/clean_texts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab1d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00e9d204",
   "metadata": {},
   "source": [
    "## Topic Modeling Process\n",
    "\n",
    "__1) Loading Preprocessed Data:__\n",
    "\n",
    "We begin by loading the preprocessed textual data from a CSV file containing cleaned text. The data is stored as a list of documents, where each document is represented as a list of words.\n",
    "\n",
    "\n",
    "__2) Text Vectorization (Bag of Words):__\n",
    "\n",
    "The text is then converted into a vector representation using the Bag of Words model. This step involves creating a dictionary (idx2word) that maps each unique word to an index and a document-term matrix (doc_term_matrix) that captures the frequency of words across documents. \n",
    "- Words that appear in fewer than 10 documents or in more than 40% of the documents are excluded to focus on meaningful and relevant terms.\n",
    "\n",
    "\n",
    "__3) Coherence Measure Computation:__\n",
    "\n",
    "To determine the optimal number of topics for the model, we compute coherence scores across a range of topic numbers (from 10 to 25). The coherence score measures the interpretability of the topics, with a higher score indicating more coherent topics. The c_v coherence type, which is based on a sliding window and uses a combination of indirect confirmation measures, is used in this analysis.\n",
    "\n",
    "\n",
    "__4) Topic Visualization:__\n",
    "\n",
    "Finally, we visualize the topics generated by the model. The `visualize_topics` function produces interactive visualizations that display the top words associated with each topic. This helps in understanding the distinct themes captured by the model.\n",
    "\n",
    "\n",
    "This process allows us to identify and interpret the latent topics within the corpus, providing valuable insights into the underlying themes present in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6524462b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecli</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECLI:NL:RBAMS:2000:AA5199</td>\n",
       "      <td>rolnummer verloop procedure terechtzitting eis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECLI:NL:RBAMS:2000:AF0022</td>\n",
       "      <td>schorsing executie ontruimingsvonnis schuldsan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECLI:NL:RBMID:2000:AF0403</td>\n",
       "      <td>oordeelt schuldsaneringsregeling ontbinding hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECLI:NL:RBROT:2000:AF0496</td>\n",
       "      <td>ontruimingsbevoegdheid belangenafweging verbod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECLI:NL:RBARN:2000:AA4293</td>\n",
       "      <td>vonnis president arrondissementsrechtbank kort...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ecli  \\\n",
       "0  ECLI:NL:RBAMS:2000:AA5199   \n",
       "1  ECLI:NL:RBAMS:2000:AF0022   \n",
       "2  ECLI:NL:RBMID:2000:AF0403   \n",
       "3  ECLI:NL:RBROT:2000:AF0496   \n",
       "4  ECLI:NL:RBARN:2000:AA4293   \n",
       "\n",
       "                                          clean_text  \n",
       "0  rolnummer verloop procedure terechtzitting eis...  \n",
       "1  schorsing executie ontruimingsvonnis schuldsan...  \n",
       "2  oordeelt schuldsaneringsregeling ontbinding hu...  \n",
       "3  ontruimingsbevoegdheid belangenafweging verbod...  \n",
       "4  vonnis president arrondissementsrechtbank kort...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) load preprocessed data\n",
    "df = pd.read_csv(\"./data/clean_texts.csv\")#, usecols=['clean_text'])\n",
    "ecli = df.ecli.tolist()\n",
    "clean_text = df.clean_text.tolist()\n",
    "docs = [txt.split(\" \") for txt in clean_text]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f69a0d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens considered: Appear in at least 10 documents and at most 40.0% of documents.\n",
      "Number of unique tokens: 7186\n",
      "Number of documents: 5021\n"
     ]
    }
   ],
   "source": [
    "# Text Vectorization (Bag of Words)\n",
    "idx2word, doc_term_matrix = prepare_topic_modeling_corpus(docs, min_doc_count=10, max_doc_proportion=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf80165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing coherence scores using \"c_v\" coherence measure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████▎                                   | 3/16 [03:43<16:15, 75.02s/it]/home/mohammad/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/text_analysis.py:448: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(\"stats accumulation interrupted; <= %d documents processed\", self._num_docs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 409, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 409, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 409, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 409, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 409, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 409, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      " 38%|████████████████▌                           | 6/16 [09:19<15:32, 93.29s/it]Process AccumulatingWorker-52:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/text_analysis.py\", line 576, in run\n",
      "    self.reply_to_master()\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/text_analysis.py\", line 600, in reply_to_master\n",
      "    self.output_q.put(self.accumulator, block=False)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 94, in put\n",
      "    self._start_thread()\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 179, in _start_thread\n",
      "    self._thread.start()\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/threading.py\", line 897, in start\n",
      "    self._started.wait()\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/threading.py\", line 574, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/home/mohammad/anaconda3/lib/python3.9/threading.py\", line 312, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# compute coherence measures for different number of topics \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ntopics_range, coherence_values \u001b[38;5;241m=\u001b[39m \u001b[43mselection_of_number_of_topics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx2word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc_term_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# the minimum number of topics\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m26\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# the maximum number of topics\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoherence_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc_v\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/github/topic-modeling-on-dutch-case-law/utils.py:229\u001b[0m, in \u001b[0;36mselection_of_number_of_topics\u001b[0;34m(idx2word, doc_term_matrix, clean_text, start, stop, step, coherence_type)\u001b[0m\n\u001b[1;32m    221\u001b[0m     coherence_model \u001b[38;5;241m=\u001b[39m CoherenceModel(\n\u001b[1;32m    222\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    223\u001b[0m         texts\u001b[38;5;241m=\u001b[39mclean_text,\n\u001b[1;32m    224\u001b[0m         dictionary\u001b[38;5;241m=\u001b[39midx2word,\n\u001b[1;32m    225\u001b[0m         coherence\u001b[38;5;241m=\u001b[39mcoherence_type  \u001b[38;5;66;03m# Options: 'c_v', 'c_uci', 'u_mass'\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(temp_file)\n\u001b[0;32m--> 229\u001b[0m     coherence_values\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcoherence_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# Save coherence values to a CSV file\u001b[39;00m\n\u001b[1;32m    232\u001b[0m coherence_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_of_topics\u001b[39m\u001b[38;5;124m\"\u001b[39m: ntopics_range, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoherence_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: coherence_values})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gensim/models/coherencemodel.py:615\u001b[0m, in \u001b[0;36mCoherenceModel.get_coherence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_coherence\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;124;03m\"\"\"Get coherence value based on pipeline parameters.\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m \n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 615\u001b[0m     confirmed_measures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence_per_topic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_measures(confirmed_measures)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gensim/models/coherencemodel.py:575\u001b[0m, in \u001b[0;36mCoherenceModel.get_coherence_per_topic\u001b[0;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[1;32m    573\u001b[0m     segmented_topics \u001b[38;5;241m=\u001b[39m measure\u001b[38;5;241m.\u001b[39mseg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopics)\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmented_topics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(with_std\u001b[38;5;241m=\u001b[39mwith_std, with_support\u001b[38;5;241m=\u001b[39mwith_support)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;129;01min\u001b[39;00m BOOLEAN_DOCUMENT_BASED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_w2v\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gensim/models/coherencemodel.py:547\u001b[0m, in \u001b[0;36mCoherenceModel.estimate_probabilities\u001b[0;34m(self, segmented_topics)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_w2v\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    545\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeyed_vectors\n\u001b[0;32m--> 547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/probability_estimation.py:156\u001b[0m, in \u001b[0;36mp_boolean_sliding_window\u001b[0;34m(texts, segmented_topics, dictionary, window_size, processes)\u001b[0m\n\u001b[1;32m    154\u001b[0m     accumulator \u001b[38;5;241m=\u001b[39m ParallelWordOccurrenceAccumulator(processes, top_ids, dictionary)\n\u001b[1;32m    155\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to estimate probabilities from sliding windows\u001b[39m\u001b[38;5;124m\"\u001b[39m, accumulator)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maccumulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/text_analysis.py:451\u001b[0m, in \u001b[0;36mParallelWordOccurrenceAccumulator.accumulate\u001b[0;34m(self, texts, window_size)\u001b[0m\n\u001b[1;32m    448\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats accumulation interrupted; <= \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m documents processed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_docs)\n\u001b[1;32m    449\u001b[0m     interrupted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m accumulators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_accumulators(accumulators)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gensim/topic_coherence/text_analysis.py:528\u001b[0m, in \u001b[0;36mParallelWordOccurrenceAccumulator.terminate_workers\u001b[0;34m(self, input_q, output_q, workers, interrupted)\u001b[0m\n\u001b[1;32m    526\u001b[0m accumulators \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accumulators) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(workers):\n\u001b[0;32m--> 528\u001b[0m     accumulators\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutput_q\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    529\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m accumulators retrieved from output queue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(accumulators))\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m worker \u001b[38;5;129;01min\u001b[39;00m workers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/connection.py:221\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/connection.py:419\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 419\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/connection.py:384\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    382\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 384\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compute coherence measures for different number of topics \n",
    "ntopics_range, coherence_values = selection_of_number_of_topics(\n",
    "    idx2word, \n",
    "    doc_term_matrix, \n",
    "    docs,\n",
    "    start=10, # the minimum number of topics\n",
    "    stop=26,  # the maximum number of topics\n",
    "    step=1,\n",
    "    coherence_type='c_v'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7727160d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/mohammad/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/mohammad/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/mohammad/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/mohammad/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/mohammad/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/mohammad/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/mohammad/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LDA visualization for model 5 to ./pics/lda_D5.html.\n"
     ]
    }
   ],
   "source": [
    "# To visualize topics by using top words\n",
    "visualize_topics(idx2word, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a8fc4",
   "metadata": {},
   "source": [
    "## Compute topic distribution within each case laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbf740bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topic distribution (for 10 topics) has been saved in ./data/topics_distribution_D10.csv.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ECLI:NL:RBAMS:2000:AA5199</th>\n",
       "      <td>0.067015</td>\n",
       "      <td>0.152803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198621</td>\n",
       "      <td>0.014613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>0.434296</td>\n",
       "      <td>0.110440</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECLI:NL:RBAMS:2000:AF0022</th>\n",
       "      <td>0.094789</td>\n",
       "      <td>0.036663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174135</td>\n",
       "      <td>0.107741</td>\n",
       "      <td>0.019224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECLI:NL:RBMID:2000:AF0403</th>\n",
       "      <td>0.065546</td>\n",
       "      <td>0.023613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406954</td>\n",
       "      <td>0.013781</td>\n",
       "      <td>0.205834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201847</td>\n",
       "      <td>0.075587</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECLI:NL:RBROT:2000:AF0496</th>\n",
       "      <td>0.120674</td>\n",
       "      <td>0.091034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360068</td>\n",
       "      <td>0.045406</td>\n",
       "      <td>0.217152</td>\n",
       "      <td>0.046998</td>\n",
       "      <td>0.018216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECLI:NL:RBARN:2000:AA4293</th>\n",
       "      <td>0.139890</td>\n",
       "      <td>0.576206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089005</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040606</td>\n",
       "      <td>0.064075</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0         1    2         3         4  \\\n",
       "ECLI:NL:RBAMS:2000:AA5199  0.067015  0.152803  0.0  0.198621  0.014613   \n",
       "ECLI:NL:RBAMS:2000:AF0022  0.094789  0.036663  0.0  0.197276  0.000000   \n",
       "ECLI:NL:RBMID:2000:AF0403  0.065546  0.023613  0.0  0.406954  0.013781   \n",
       "ECLI:NL:RBROT:2000:AF0496  0.120674  0.091034  0.0  0.096353  0.000000   \n",
       "ECLI:NL:RBARN:2000:AA4293  0.139890  0.576206  0.0  0.000000  0.089005   \n",
       "\n",
       "                                  5         6         7         8         9  \n",
       "ECLI:NL:RBAMS:2000:AA5199  0.000000  0.012703  0.434296  0.110440  0.000000  \n",
       "ECLI:NL:RBAMS:2000:AF0022  0.362863  0.000000  0.174135  0.107741  0.019224  \n",
       "ECLI:NL:RBMID:2000:AF0403  0.205834  0.000000  0.201847  0.075587  0.000000  \n",
       "ECLI:NL:RBROT:2000:AF0496  0.360068  0.045406  0.217152  0.046998  0.018216  \n",
       "ECLI:NL:RBARN:2000:AA4293  0.079133  0.000000  0.040606  0.064075  0.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import generate_topic_distributions\n",
    "\n",
    "ntopics = 10\n",
    "\n",
    "df_embedding = generate_topic_distributions(ecli, doc_term_matrix, ntopics)\n",
    "\n",
    "csv_file = f'./data/topics_distribution_D{ntopics}.csv'\n",
    "df_embedding.to_csv(csv_file)\n",
    "print(f\"The topic distribution (for {ntopics} topics) has been saved in {csv_file}.\")\n",
    "\n",
    "df_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8af4e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5021, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ECLI:NL:RBAMS:2000:AA5199</th>\n",
       "      <td>0.067015</td>\n",
       "      <td>0.152803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198621</td>\n",
       "      <td>0.014613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>0.434296</td>\n",
       "      <td>0.110440</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECLI:NL:RBAMS:2000:AF0022</th>\n",
       "      <td>0.094789</td>\n",
       "      <td>0.036663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174135</td>\n",
       "      <td>0.107741</td>\n",
       "      <td>0.019224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECLI:NL:RBMID:2000:AF0403</th>\n",
       "      <td>0.065546</td>\n",
       "      <td>0.023613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406954</td>\n",
       "      <td>0.013781</td>\n",
       "      <td>0.205834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201847</td>\n",
       "      <td>0.075587</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECLI:NL:RBROT:2000:AF0496</th>\n",
       "      <td>0.120674</td>\n",
       "      <td>0.091034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360068</td>\n",
       "      <td>0.045406</td>\n",
       "      <td>0.217152</td>\n",
       "      <td>0.046998</td>\n",
       "      <td>0.018216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECLI:NL:RBARN:2000:AA4293</th>\n",
       "      <td>0.139890</td>\n",
       "      <td>0.576206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089005</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040606</td>\n",
       "      <td>0.064075</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0         1    2         3         4  \\\n",
       "ECLI:NL:RBAMS:2000:AA5199  0.067015  0.152803  0.0  0.198621  0.014613   \n",
       "ECLI:NL:RBAMS:2000:AF0022  0.094789  0.036663  0.0  0.197276  0.000000   \n",
       "ECLI:NL:RBMID:2000:AF0403  0.065546  0.023613  0.0  0.406954  0.013781   \n",
       "ECLI:NL:RBROT:2000:AF0496  0.120674  0.091034  0.0  0.096353  0.000000   \n",
       "ECLI:NL:RBARN:2000:AA4293  0.139890  0.576206  0.0  0.000000  0.089005   \n",
       "\n",
       "                                  5         6         7         8         9  \n",
       "ECLI:NL:RBAMS:2000:AA5199  0.000000  0.012703  0.434296  0.110440  0.000000  \n",
       "ECLI:NL:RBAMS:2000:AF0022  0.362863  0.000000  0.174135  0.107741  0.019224  \n",
       "ECLI:NL:RBMID:2000:AF0403  0.205834  0.000000  0.201847  0.075587  0.000000  \n",
       "ECLI:NL:RBROT:2000:AF0496  0.360068  0.045406  0.217152  0.046998  0.018216  \n",
       "ECLI:NL:RBARN:2000:AA4293  0.079133  0.000000  0.040606  0.064075  0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63994dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f2a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a360ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
